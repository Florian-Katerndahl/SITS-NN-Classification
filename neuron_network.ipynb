{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "# from torchmetrics import R2Score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='D:\\\\Deutschland\\\\FUB\\\\master_thesis\\\\data\\\\gee\\\\output'\n",
    "DATA_DIR = os.path.join(PATH, 'monthly_mean')\n",
    "LABEL_CSV = 'label.csv'\n",
    "\n",
    "label_path = os.path.join(PATH, LABEL_CSV)\n",
    "files = os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LR = 0.01\n",
    "EPOCH = 500\n",
    "\n",
    "input_size = 3\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "layer1_dim = 400\n",
    "layer2_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load csv file to ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(label_path, sep=',', header=0, index_col=['id'])\n",
    "x_list = []\n",
    "y_list = []\n",
    "for index, row in labels.iterrows():\n",
    "    df_path = os.path.join(DATA_DIR, f'{index}.csv')\n",
    "    df = pd.read_csv(df_path, sep=',', header=0, index_col=['date'])\n",
    "    x = np.array(df, dtype=int)\n",
    "    x = x.reshape(-1)\n",
    "    y = row[0]\n",
    "    x_list.append(x)\n",
    "    y_list.append(y)\n",
    "\n",
    "x_data = np.array(x_list)\n",
    "y_data = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7935,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "embedding = nn.Embedding(8000, 3)\n",
    "x_set = torch.from_numpy(x_data)\n",
    "y_set = torch.from_numpy(y_data)\n",
    "x_set = embedding(x_set).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "dataset = Data.TensorDataset(x_set, y_set)\n",
    "size = len(dataset)\n",
    "train_size, test_size = round(0.8 * size), round(0.2 * size)\n",
    "train_dataset, test_dataset = Data.random_split(dataset, [train_size, test_size])\n",
    "# data_loader\n",
    "train_loader = Data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "test_loader = Data.DataLoader(test_dataset,batch_size=test_size, shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuron network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc0 = nn.Linear(275, 512)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "class simpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, layer1_dim, layer2_dim, num_layers, num_classes):\n",
    "        super(simpleLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear1 = nn.Linear(hidden_size, layer1_dim, layer2_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(layer1_dim, layer2_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc = nn.Linear(layer2_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "        tmp1 = self.relu1(self.linear1(lstm_out[:,-1,:]))\n",
    "        tmp2 = self.relu2(self.linear2(tmp1))\n",
    "        out = self.fc(tmp2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simpleLSTM(input_size, hidden_size, layer1_dim, layer2_dim, num_layers, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, epoch:int):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (inputs, target) in enumerate(train_loader, 0):\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + update\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print('[Epoch %d] loss: %.3f' % (epoch + 1, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/500],Step[50/50],Loss:1.7979,Accuracy:28.12%\n",
      "Epoch[2/500],Step[50/50],Loss:1.9120,Accuracy:24.22%\n",
      "Epoch[3/500],Step[50/50],Loss:2.0677,Accuracy:23.44%\n",
      "Epoch[4/500],Step[50/50],Loss:1.8586,Accuracy:25.78%\n",
      "Epoch[5/500],Step[50/50],Loss:1.8451,Accuracy:35.94%\n",
      "Epoch[6/500],Step[50/50],Loss:1.8673,Accuracy:21.88%\n",
      "Epoch[7/500],Step[50/50],Loss:1.8265,Accuracy:32.03%\n",
      "Epoch[8/500],Step[50/50],Loss:1.9940,Accuracy:24.22%\n",
      "Epoch[9/500],Step[50/50],Loss:2.0662,Accuracy:25.00%\n",
      "Epoch[10/500],Step[50/50],Loss:1.8601,Accuracy:30.47%\n",
      "Epoch[11/500],Step[50/50],Loss:1.7805,Accuracy:28.91%\n",
      "Epoch[12/500],Step[50/50],Loss:1.7475,Accuracy:37.50%\n",
      "Epoch[13/500],Step[50/50],Loss:1.6781,Accuracy:32.81%\n",
      "Epoch[14/500],Step[50/50],Loss:1.7473,Accuracy:32.81%\n",
      "Epoch[15/500],Step[50/50],Loss:1.5951,Accuracy:35.94%\n",
      "Epoch[16/500],Step[50/50],Loss:1.4539,Accuracy:40.62%\n",
      "Epoch[17/500],Step[50/50],Loss:1.4031,Accuracy:53.12%\n",
      "Epoch[18/500],Step[50/50],Loss:1.4018,Accuracy:49.22%\n",
      "Epoch[19/500],Step[50/50],Loss:1.1626,Accuracy:57.03%\n",
      "Epoch[20/500],Step[50/50],Loss:1.1175,Accuracy:57.81%\n",
      "Epoch[21/500],Step[50/50],Loss:0.9601,Accuracy:64.06%\n",
      "Epoch[22/500],Step[50/50],Loss:0.8782,Accuracy:64.06%\n",
      "Epoch[23/500],Step[50/50],Loss:0.9600,Accuracy:61.72%\n",
      "Epoch[24/500],Step[50/50],Loss:0.7956,Accuracy:71.88%\n",
      "Epoch[25/500],Step[50/50],Loss:0.7775,Accuracy:71.09%\n",
      "Epoch[26/500],Step[50/50],Loss:0.6122,Accuracy:75.78%\n",
      "Epoch[27/500],Step[50/50],Loss:0.5221,Accuracy:78.12%\n",
      "Epoch[28/500],Step[50/50],Loss:0.4747,Accuracy:83.59%\n",
      "Epoch[29/500],Step[50/50],Loss:0.3343,Accuracy:90.62%\n",
      "Epoch[30/500],Step[50/50],Loss:0.5451,Accuracy:85.94%\n",
      "Epoch[31/500],Step[50/50],Loss:0.3545,Accuracy:89.06%\n",
      "Epoch[32/500],Step[50/50],Loss:0.3060,Accuracy:90.62%\n",
      "Epoch[33/500],Step[50/50],Loss:0.3100,Accuracy:90.62%\n",
      "Epoch[34/500],Step[50/50],Loss:0.2622,Accuracy:89.84%\n",
      "Epoch[35/500],Step[50/50],Loss:0.2843,Accuracy:92.19%\n",
      "Epoch[36/500],Step[50/50],Loss:0.2438,Accuracy:95.31%\n",
      "Epoch[37/500],Step[50/50],Loss:0.2140,Accuracy:89.84%\n",
      "Epoch[38/500],Step[50/50],Loss:0.1833,Accuracy:94.53%\n",
      "Epoch[39/500],Step[50/50],Loss:0.1122,Accuracy:97.66%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Codes\\python\\TSC_CNN\\dongshen\\neuron_network.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Codes/python/TSC_CNN/dongshen/neuron_network.ipynb#ch0000017?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Codes/python/TSC_CNN/dongshen/neuron_network.ipynb#ch0000017?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCH):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Codes/python/TSC_CNN/dongshen/neuron_network.ipynb#ch0000017?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (\u001b[39minput\u001b[39m, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Codes/python/TSC_CNN/dongshen/neuron_network.ipynb#ch0000017?line=6'>7</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Codes/python/TSC_CNN/dongshen/neuron_network.ipynb#ch0000017?line=7'>8</a>\u001b[0m         label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:355\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=352'>353</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=353'>354</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32md:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:301\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=298'>299</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=299'>300</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=300'>301</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32md:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:914\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=906'>907</a>\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=907'>908</a>\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=908'>909</a>\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=909'>910</a>\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=910'>911</a>\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=911'>912</a>\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=912'>913</a>\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=913'>914</a>\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=914'>915</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/site-packages/torch/utils/data/dataloader.py?line=915'>916</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32md:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/process.py?line=117'>118</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/process.py?line=118'>119</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/process.py?line=119'>120</a>\u001b[0m _cleanup()\n\u001b[1;32m--> <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/process.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/process.py?line=121'>122</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/process.py?line=122'>123</a>\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/process.py?line=123'>124</a>\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32md:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/context.py?line=221'>222</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/context.py?line=222'>223</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/context.py?line=223'>224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32md:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/context.py?line=323'>324</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/context.py?line=324'>325</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/context.py?line=325'>326</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/context.py?line=326'>327</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32md:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/popen_spawn_win32.py?line=90'>91</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/popen_spawn_win32.py?line=91'>92</a>\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/popen_spawn_win32.py?line=92'>93</a>\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/popen_spawn_win32.py?line=93'>94</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/popen_spawn_win32.py?line=94'>95</a>\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/reduction.py?line=57'>58</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/reduction.py?line=58'>59</a>\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> <a href='file:///d%3A/LenovoSoftstore/Anaconda/envs/yolov5/lib/multiprocessing/reduction.py?line=59'>60</a>\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "total_step = len(train_loader)\n",
    "acc_list = []\n",
    "model.train()\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (input, label) in enumerate(train_loader):\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "        # forward pass\n",
    "        output = model(input)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 记录精度\n",
    "        total = label.size(0)\n",
    "        # torch.max(x,1) 按行取最大值\n",
    "        # output每一行的最大值存在_中，每一行最大值的索引存在predicted中\n",
    "        # output的每一行的每个元素的值表示是这一类的概率，取最大概率所对应的类作为分类结果\n",
    "        # 也就是找到最大概率的索引\n",
    "        _,predicted = torch.max(output.data,1)\n",
    "        # .sum()计算出predicted和label相同的元素有多少个，返回的是一个张量，.item()得到这个张量的数值(int型)\n",
    "        correct = (predicted == label).sum().item()\n",
    "        acc_list.append(correct/total)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('Epoch[{}/{}],Step[{}/{}],Loss:{:.4f},Accuracy:{:.2f}%'\n",
    "            .format(epoch+1,EPOCH,i+50,total_step,loss.item(),(correct/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 78.89098928796471 %\n"
     ]
    }
   ],
   "source": [
    "# validate the model\n",
    "# model = torch.load('\\model.pkl')\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for (value, label) in test_loader:\n",
    "        value = value.to(device)\n",
    "        label = label.to(device)\n",
    "        outputs = model(value)\n",
    "        total += label.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == label).sum().item()\n",
    "    print('Test Accuracy of the model: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module):\n",
    "    model.eval()\n",
    "    r2 = 0.\n",
    "    with torch.no_grad():\n",
    "        for (values, labels) in test_loader:\n",
    "            values = values.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(values)\n",
    "            num = labels.size(0)\n",
    "            # transpose matrics\n",
    "            outputs = outputs.t()\n",
    "            labels = labels.t()\n",
    "            r2score = R2Score(num_outputs=num, multioutput='uniform_average').to(device)\n",
    "            r2 = r2score(labels, outputs).item()\n",
    "    print('R^2 on test set: %.2f' % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57200abac2ff18432c53e10587ceb364acdd46eebe90c6833204d1f95e2c9eff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
