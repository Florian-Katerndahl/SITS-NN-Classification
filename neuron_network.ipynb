{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import R2Score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='D:\\\\Deutschland\\\\FUB\\\\master_thesis\\\\data\\\\gee\\\\output'\n",
    "DATA_DIR = os.path.join(PATH, 'monthly_mean')\n",
    "LABEL_CSV = 'labels.csv'\n",
    "\n",
    "label_path = os.path.join(PATH, LABEL_CSV)\n",
    "files = os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LR = 0.005\n",
    "MOMENTUM = 0.5\n",
    "EPOCH = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load csv file to ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(label_path, sep=',', header=0, index_col=['id'])\n",
    "x_list = []\n",
    "y_list = []\n",
    "for index, row in labels.iterrows():\n",
    "    df_path = os.path.join(DATA_DIR, f'{index}.csv')\n",
    "    df = pd.read_csv(df_path, sep=',', header=0, index_col=None)\n",
    "    x_list.append(np.array(df))\n",
    "    y_list.append(np.array(row))\n",
    "\n",
    "x_data = np.array(x_list)\n",
    "y_data = np.array(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set = torch.from_numpy(x_data).float()\n",
    "y_set = torch.from_numpy(y_data).float()\n",
    "# split dataset\n",
    "dataset = Data.TensorDataset(x_set, y_set)\n",
    "size = len(dataset)\n",
    "train_size, test_size = round(0.8 * size), round(0.2 * size)\n",
    "train_dataset, test_dataset = Data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = Data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "test_loader = Data.DataLoader(test_dataset,batch_size=test_size, shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuron network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(275, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()\n",
    "model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for batch_idx, (inputs, target) in enumerate(train_loader, 0):\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + update\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('[Epoch %d] loss: %.3f' % (epoch + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            values, labels = data\n",
    "            values = values.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(values)\n",
    "            num = labels.size(0)\n",
    "            # transpose matrics\n",
    "            outputs = outputs.t()\n",
    "            labels = labels.t()\n",
    "            r2score = R2Score(num_outputs=num, multioutput='uniform_average').to(device)\n",
    "            r2 = r2score(labels, outputs).item()\n",
    "    print('R^2 on test set: %.2f' % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss: 0.761\n",
      "[Epoch 2] loss: 0.787\n",
      "[Epoch 3] loss: 0.734\n",
      "[Epoch 4] loss: 0.781\n",
      "[Epoch 5] loss: 0.809\n",
      "[Epoch 6] loss: 0.793\n",
      "[Epoch 7] loss: 0.790\n",
      "[Epoch 8] loss: 0.798\n",
      "[Epoch 9] loss: 0.775\n",
      "[Epoch 10] loss: 0.798\n",
      "[Epoch 11] loss: 0.755\n",
      "[Epoch 12] loss: 0.793\n",
      "[Epoch 13] loss: 0.770\n",
      "[Epoch 14] loss: 0.761\n",
      "[Epoch 15] loss: 0.793\n",
      "[Epoch 16] loss: 0.775\n",
      "[Epoch 17] loss: 0.765\n",
      "[Epoch 18] loss: 0.794\n",
      "[Epoch 19] loss: 0.804\n",
      "[Epoch 20] loss: 0.755\n",
      "[Epoch 21] loss: 0.798\n",
      "[Epoch 22] loss: 0.768\n",
      "[Epoch 23] loss: 0.776\n",
      "[Epoch 24] loss: 0.787\n",
      "[Epoch 25] loss: 0.766\n",
      "[Epoch 26] loss: 0.804\n",
      "[Epoch 27] loss: 0.782\n",
      "[Epoch 28] loss: 0.790\n",
      "[Epoch 29] loss: 0.759\n",
      "[Epoch 30] loss: 0.790\n",
      "[Epoch 31] loss: 0.776\n",
      "[Epoch 32] loss: 0.783\n",
      "[Epoch 33] loss: 0.774\n",
      "[Epoch 34] loss: 0.758\n",
      "[Epoch 35] loss: 0.759\n",
      "[Epoch 36] loss: 0.807\n",
      "[Epoch 37] loss: 0.804\n",
      "[Epoch 38] loss: 0.776\n",
      "[Epoch 39] loss: 0.783\n",
      "[Epoch 40] loss: 0.759\n",
      "[Epoch 41] loss: 0.789\n",
      "[Epoch 42] loss: 0.795\n",
      "[Epoch 43] loss: 0.792\n",
      "[Epoch 44] loss: 0.792\n",
      "[Epoch 45] loss: 0.778\n",
      "[Epoch 46] loss: 0.815\n",
      "[Epoch 47] loss: 0.792\n",
      "[Epoch 48] loss: 0.770\n",
      "[Epoch 49] loss: 0.761\n",
      "[Epoch 50] loss: 0.761\n",
      "[Epoch 51] loss: 0.774\n",
      "[Epoch 52] loss: 0.789\n",
      "[Epoch 53] loss: 0.789\n",
      "[Epoch 54] loss: 0.790\n",
      "[Epoch 55] loss: 0.816\n",
      "[Epoch 56] loss: 0.797\n",
      "[Epoch 57] loss: 0.776\n",
      "[Epoch 58] loss: 0.782\n",
      "[Epoch 59] loss: 0.792\n",
      "[Epoch 60] loss: 0.791\n",
      "[Epoch 61] loss: 0.749\n",
      "[Epoch 62] loss: 0.783\n",
      "[Epoch 63] loss: 0.801\n",
      "[Epoch 64] loss: 0.782\n",
      "[Epoch 65] loss: 0.773\n",
      "[Epoch 66] loss: 0.817\n",
      "[Epoch 67] loss: 0.762\n",
      "[Epoch 68] loss: 0.757\n",
      "[Epoch 69] loss: 0.799\n",
      "[Epoch 70] loss: 0.768\n",
      "[Epoch 71] loss: 0.761\n",
      "[Epoch 72] loss: 0.801\n",
      "[Epoch 73] loss: 0.781\n",
      "[Epoch 74] loss: 0.786\n",
      "[Epoch 75] loss: 0.800\n",
      "[Epoch 76] loss: 0.781\n",
      "[Epoch 77] loss: 0.780\n",
      "[Epoch 78] loss: 0.771\n",
      "[Epoch 79] loss: 0.789\n",
      "[Epoch 80] loss: 0.813\n",
      "[Epoch 81] loss: 0.797\n",
      "[Epoch 82] loss: 0.784\n",
      "[Epoch 83] loss: 0.812\n",
      "[Epoch 84] loss: 0.772\n",
      "[Epoch 85] loss: 0.771\n",
      "[Epoch 86] loss: 0.785\n",
      "[Epoch 87] loss: 0.797\n",
      "[Epoch 88] loss: 0.779\n",
      "[Epoch 89] loss: 0.778\n",
      "[Epoch 90] loss: 0.783\n",
      "[Epoch 91] loss: 0.809\n",
      "[Epoch 92] loss: 0.774\n",
      "[Epoch 93] loss: 0.747\n",
      "[Epoch 94] loss: 0.783\n",
      "[Epoch 95] loss: 0.787\n",
      "[Epoch 96] loss: 0.787\n",
      "[Epoch 97] loss: 0.792\n",
      "[Epoch 98] loss: 0.792\n",
      "[Epoch 99] loss: 0.752\n",
      "[Epoch 100] loss: 0.749\n",
      "[Epoch 101] loss: 0.793\n",
      "[Epoch 102] loss: 0.759\n",
      "[Epoch 103] loss: 0.739\n",
      "[Epoch 104] loss: 0.772\n",
      "[Epoch 105] loss: 0.790\n",
      "[Epoch 106] loss: 0.800\n",
      "[Epoch 107] loss: 0.767\n",
      "[Epoch 108] loss: 0.819\n",
      "[Epoch 109] loss: 0.785\n",
      "[Epoch 110] loss: 0.770\n",
      "[Epoch 111] loss: 0.783\n",
      "[Epoch 112] loss: 0.797\n",
      "[Epoch 113] loss: 0.754\n",
      "[Epoch 114] loss: 0.803\n",
      "[Epoch 115] loss: 0.760\n",
      "[Epoch 116] loss: 0.768\n",
      "[Epoch 117] loss: 0.797\n",
      "[Epoch 118] loss: 0.799\n",
      "[Epoch 119] loss: 0.805\n",
      "[Epoch 120] loss: 0.782\n",
      "[Epoch 121] loss: 0.783\n",
      "[Epoch 122] loss: 0.752\n",
      "[Epoch 123] loss: 0.795\n",
      "[Epoch 124] loss: 0.758\n",
      "[Epoch 125] loss: 0.786\n",
      "[Epoch 126] loss: 0.773\n",
      "[Epoch 127] loss: 0.790\n",
      "[Epoch 128] loss: 0.762\n",
      "[Epoch 129] loss: 0.792\n",
      "[Epoch 130] loss: 0.789\n",
      "[Epoch 131] loss: 0.758\n",
      "[Epoch 132] loss: 0.780\n",
      "[Epoch 133] loss: 0.762\n",
      "[Epoch 134] loss: 0.798\n",
      "[Epoch 135] loss: 0.773\n",
      "[Epoch 136] loss: 0.777\n",
      "[Epoch 137] loss: 0.795\n",
      "[Epoch 138] loss: 0.807\n",
      "[Epoch 139] loss: 0.770\n",
      "[Epoch 140] loss: 0.768\n",
      "[Epoch 141] loss: 0.772\n",
      "[Epoch 142] loss: 0.777\n",
      "[Epoch 143] loss: 0.796\n",
      "[Epoch 144] loss: 0.765\n",
      "[Epoch 145] loss: 0.795\n",
      "[Epoch 146] loss: 0.770\n",
      "[Epoch 147] loss: 0.759\n",
      "[Epoch 148] loss: 0.769\n",
      "[Epoch 149] loss: 0.768\n",
      "[Epoch 150] loss: 0.748\n",
      "[Epoch 151] loss: 0.781\n",
      "[Epoch 152] loss: 0.806\n",
      "[Epoch 153] loss: 0.777\n",
      "[Epoch 154] loss: 0.790\n",
      "[Epoch 155] loss: 0.786\n",
      "[Epoch 156] loss: 0.802\n",
      "[Epoch 157] loss: 0.771\n",
      "[Epoch 158] loss: 0.786\n",
      "[Epoch 159] loss: 0.777\n",
      "[Epoch 160] loss: 0.792\n",
      "[Epoch 161] loss: 0.766\n",
      "[Epoch 162] loss: 0.749\n",
      "[Epoch 163] loss: 0.762\n",
      "[Epoch 164] loss: 0.780\n",
      "[Epoch 165] loss: 0.782\n",
      "[Epoch 166] loss: 0.783\n",
      "[Epoch 167] loss: 0.787\n",
      "[Epoch 168] loss: 0.786\n",
      "[Epoch 169] loss: 0.779\n",
      "[Epoch 170] loss: 0.771\n",
      "[Epoch 171] loss: 0.746\n",
      "[Epoch 172] loss: 0.785\n",
      "[Epoch 173] loss: 0.795\n",
      "[Epoch 174] loss: 0.782\n",
      "[Epoch 175] loss: 0.806\n",
      "[Epoch 176] loss: 0.808\n",
      "[Epoch 177] loss: 0.764\n",
      "[Epoch 178] loss: 0.780\n",
      "[Epoch 179] loss: 0.784\n",
      "[Epoch 180] loss: 0.802\n",
      "[Epoch 181] loss: 0.747\n",
      "[Epoch 182] loss: 0.776\n",
      "[Epoch 183] loss: 0.810\n",
      "[Epoch 184] loss: 0.792\n",
      "[Epoch 185] loss: 0.761\n",
      "[Epoch 186] loss: 0.796\n",
      "[Epoch 187] loss: 0.798\n",
      "[Epoch 188] loss: 0.817\n",
      "[Epoch 189] loss: 0.795\n",
      "[Epoch 190] loss: 0.768\n",
      "[Epoch 191] loss: 0.759\n",
      "[Epoch 192] loss: 0.759\n",
      "[Epoch 193] loss: 0.789\n",
      "[Epoch 194] loss: 0.790\n",
      "[Epoch 195] loss: 0.757\n",
      "[Epoch 196] loss: 0.808\n",
      "[Epoch 197] loss: 0.793\n",
      "[Epoch 198] loss: 0.786\n",
      "[Epoch 199] loss: 0.751\n",
      "[Epoch 200] loss: 0.799\n",
      "[Epoch 201] loss: 0.783\n",
      "[Epoch 202] loss: 0.776\n",
      "[Epoch 203] loss: 0.793\n",
      "[Epoch 204] loss: 0.786\n",
      "[Epoch 205] loss: 0.779\n",
      "[Epoch 206] loss: 0.776\n",
      "[Epoch 207] loss: 0.789\n",
      "[Epoch 208] loss: 0.781\n",
      "[Epoch 209] loss: 0.782\n",
      "[Epoch 210] loss: 0.792\n",
      "[Epoch 211] loss: 0.785\n",
      "[Epoch 212] loss: 0.777\n",
      "[Epoch 213] loss: 0.798\n",
      "[Epoch 214] loss: 0.793\n",
      "[Epoch 215] loss: 0.794\n",
      "[Epoch 216] loss: 0.792\n",
      "[Epoch 217] loss: 0.780\n",
      "[Epoch 218] loss: 0.782\n",
      "[Epoch 219] loss: 0.771\n",
      "[Epoch 220] loss: 0.777\n",
      "[Epoch 221] loss: 0.770\n",
      "[Epoch 222] loss: 0.778\n",
      "[Epoch 223] loss: 0.783\n",
      "[Epoch 224] loss: 0.783\n",
      "[Epoch 225] loss: 0.796\n",
      "[Epoch 226] loss: 0.801\n",
      "[Epoch 227] loss: 0.764\n",
      "[Epoch 228] loss: 0.758\n",
      "[Epoch 229] loss: 0.799\n",
      "[Epoch 230] loss: 0.776\n",
      "[Epoch 231] loss: 0.783\n",
      "[Epoch 232] loss: 0.824\n",
      "[Epoch 233] loss: 0.790\n",
      "[Epoch 234] loss: 0.782\n",
      "[Epoch 235] loss: 0.758\n",
      "[Epoch 236] loss: 0.754\n",
      "[Epoch 237] loss: 0.789\n",
      "[Epoch 238] loss: 0.757\n",
      "[Epoch 239] loss: 0.767\n",
      "[Epoch 240] loss: 0.809\n",
      "[Epoch 241] loss: 0.808\n",
      "[Epoch 242] loss: 0.790\n",
      "[Epoch 243] loss: 0.781\n",
      "[Epoch 244] loss: 0.800\n",
      "[Epoch 245] loss: 0.788\n",
      "[Epoch 246] loss: 0.784\n",
      "[Epoch 247] loss: 0.777\n",
      "[Epoch 248] loss: 0.781\n",
      "[Epoch 249] loss: 0.812\n",
      "[Epoch 250] loss: 0.768\n",
      "[Epoch 251] loss: 0.772\n",
      "[Epoch 252] loss: 0.790\n",
      "[Epoch 253] loss: 0.786\n",
      "[Epoch 254] loss: 0.790\n",
      "[Epoch 255] loss: 0.781\n",
      "[Epoch 256] loss: 0.800\n",
      "[Epoch 257] loss: 0.786\n",
      "[Epoch 258] loss: 0.788\n",
      "[Epoch 259] loss: 0.754\n",
      "[Epoch 260] loss: 0.784\n",
      "[Epoch 261] loss: 0.767\n",
      "[Epoch 262] loss: 0.782\n",
      "[Epoch 263] loss: 0.767\n",
      "[Epoch 264] loss: 0.780\n",
      "[Epoch 265] loss: 0.787\n",
      "[Epoch 266] loss: 0.781\n",
      "[Epoch 267] loss: 0.770\n",
      "[Epoch 268] loss: 0.776\n",
      "[Epoch 269] loss: 0.773\n",
      "[Epoch 270] loss: 0.773\n",
      "[Epoch 271] loss: 0.799\n",
      "[Epoch 272] loss: 0.780\n",
      "[Epoch 273] loss: 0.773\n",
      "[Epoch 274] loss: 0.795\n",
      "[Epoch 275] loss: 0.772\n",
      "[Epoch 276] loss: 0.758\n",
      "[Epoch 277] loss: 0.805\n",
      "[Epoch 278] loss: 0.789\n",
      "[Epoch 279] loss: 0.792\n",
      "[Epoch 280] loss: 0.777\n",
      "[Epoch 281] loss: 0.792\n",
      "[Epoch 282] loss: 0.770\n",
      "[Epoch 283] loss: 0.793\n",
      "[Epoch 284] loss: 0.793\n",
      "[Epoch 285] loss: 0.770\n",
      "[Epoch 286] loss: 0.763\n",
      "[Epoch 287] loss: 0.797\n",
      "[Epoch 288] loss: 0.771\n",
      "[Epoch 289] loss: 0.757\n",
      "[Epoch 290] loss: 0.772\n",
      "[Epoch 291] loss: 0.782\n",
      "[Epoch 292] loss: 0.792\n",
      "[Epoch 293] loss: 0.768\n",
      "[Epoch 294] loss: 0.792\n",
      "[Epoch 295] loss: 0.758\n",
      "[Epoch 296] loss: 0.769\n",
      "[Epoch 297] loss: 0.789\n",
      "[Epoch 298] loss: 0.748\n",
      "[Epoch 299] loss: 0.784\n",
      "[Epoch 300] loss: 0.784\n",
      "[Epoch 301] loss: 0.756\n",
      "[Epoch 302] loss: 0.802\n",
      "[Epoch 303] loss: 0.752\n",
      "[Epoch 304] loss: 0.809\n",
      "[Epoch 305] loss: 0.805\n",
      "[Epoch 306] loss: 0.795\n",
      "[Epoch 307] loss: 0.798\n",
      "[Epoch 308] loss: 0.783\n",
      "[Epoch 309] loss: 0.779\n",
      "[Epoch 310] loss: 0.795\n",
      "[Epoch 311] loss: 0.816\n",
      "[Epoch 312] loss: 0.805\n",
      "[Epoch 313] loss: 0.787\n",
      "[Epoch 314] loss: 0.778\n",
      "[Epoch 315] loss: 0.782\n",
      "[Epoch 316] loss: 0.778\n",
      "[Epoch 317] loss: 0.794\n",
      "[Epoch 318] loss: 0.789\n",
      "[Epoch 319] loss: 0.768\n",
      "[Epoch 320] loss: 0.784\n",
      "[Epoch 321] loss: 0.773\n",
      "[Epoch 322] loss: 0.783\n",
      "[Epoch 323] loss: 0.773\n",
      "[Epoch 324] loss: 0.781\n",
      "[Epoch 325] loss: 0.780\n",
      "[Epoch 326] loss: 0.787\n",
      "[Epoch 327] loss: 0.777\n",
      "[Epoch 328] loss: 0.801\n",
      "[Epoch 329] loss: 0.790\n",
      "[Epoch 330] loss: 0.784\n",
      "[Epoch 331] loss: 0.772\n",
      "[Epoch 332] loss: 0.784\n",
      "[Epoch 333] loss: 0.772\n",
      "[Epoch 334] loss: 0.798\n",
      "[Epoch 335] loss: 0.781\n",
      "[Epoch 336] loss: 0.764\n",
      "[Epoch 337] loss: 0.779\n",
      "[Epoch 338] loss: 0.777\n",
      "[Epoch 339] loss: 0.781\n",
      "[Epoch 340] loss: 0.778\n",
      "[Epoch 341] loss: 0.761\n",
      "[Epoch 342] loss: 0.782\n",
      "[Epoch 343] loss: 0.771\n",
      "[Epoch 344] loss: 0.738\n",
      "[Epoch 345] loss: 0.779\n",
      "[Epoch 346] loss: 0.795\n",
      "[Epoch 347] loss: 0.781\n",
      "[Epoch 348] loss: 0.802\n",
      "[Epoch 349] loss: 0.763\n",
      "[Epoch 350] loss: 0.802\n",
      "[Epoch 351] loss: 0.759\n",
      "[Epoch 352] loss: 0.777\n",
      "[Epoch 353] loss: 0.773\n",
      "[Epoch 354] loss: 0.806\n",
      "[Epoch 355] loss: 0.776\n",
      "[Epoch 356] loss: 0.779\n",
      "[Epoch 357] loss: 0.774\n",
      "[Epoch 358] loss: 0.812\n",
      "[Epoch 359] loss: 0.752\n",
      "[Epoch 360] loss: 0.788\n",
      "[Epoch 361] loss: 0.791\n",
      "[Epoch 362] loss: 0.787\n",
      "[Epoch 363] loss: 0.784\n",
      "[Epoch 364] loss: 0.782\n",
      "[Epoch 365] loss: 0.782\n",
      "[Epoch 366] loss: 0.751\n",
      "[Epoch 367] loss: 0.793\n",
      "[Epoch 368] loss: 0.806\n",
      "[Epoch 369] loss: 0.781\n",
      "[Epoch 370] loss: 0.774\n",
      "[Epoch 371] loss: 0.774\n",
      "[Epoch 372] loss: 0.750\n",
      "[Epoch 373] loss: 0.784\n",
      "[Epoch 374] loss: 0.797\n",
      "[Epoch 375] loss: 0.787\n",
      "[Epoch 376] loss: 0.779\n",
      "[Epoch 377] loss: 0.784\n",
      "[Epoch 378] loss: 0.790\n",
      "[Epoch 379] loss: 0.761\n",
      "[Epoch 380] loss: 0.793\n",
      "[Epoch 381] loss: 0.768\n",
      "[Epoch 382] loss: 0.774\n",
      "[Epoch 383] loss: 0.790\n",
      "[Epoch 384] loss: 0.789\n",
      "[Epoch 385] loss: 0.777\n",
      "[Epoch 386] loss: 0.782\n",
      "[Epoch 387] loss: 0.793\n",
      "[Epoch 388] loss: 0.795\n",
      "[Epoch 389] loss: 0.776\n",
      "[Epoch 390] loss: 0.771\n",
      "[Epoch 391] loss: 0.768\n",
      "[Epoch 392] loss: 0.755\n",
      "[Epoch 393] loss: 0.800\n",
      "[Epoch 394] loss: 0.783\n",
      "[Epoch 395] loss: 0.779\n",
      "[Epoch 396] loss: 0.776\n",
      "[Epoch 397] loss: 0.779\n",
      "[Epoch 398] loss: 0.787\n",
      "[Epoch 399] loss: 0.784\n",
      "[Epoch 400] loss: 0.777\n",
      "[Epoch 401] loss: 0.811\n",
      "[Epoch 402] loss: 0.784\n",
      "[Epoch 403] loss: 0.755\n",
      "[Epoch 404] loss: 0.781\n",
      "[Epoch 405] loss: 0.786\n",
      "[Epoch 406] loss: 0.764\n",
      "[Epoch 407] loss: 0.783\n",
      "[Epoch 408] loss: 0.805\n",
      "[Epoch 409] loss: 0.770\n",
      "[Epoch 410] loss: 0.780\n",
      "[Epoch 411] loss: 0.768\n",
      "[Epoch 412] loss: 0.805\n",
      "[Epoch 413] loss: 0.746\n",
      "[Epoch 414] loss: 0.770\n",
      "[Epoch 415] loss: 0.786\n",
      "[Epoch 416] loss: 0.780\n",
      "[Epoch 417] loss: 0.798\n",
      "[Epoch 418] loss: 0.805\n",
      "[Epoch 419] loss: 0.781\n",
      "[Epoch 420] loss: 0.756\n",
      "[Epoch 421] loss: 0.799\n",
      "[Epoch 422] loss: 0.807\n",
      "[Epoch 423] loss: 0.758\n",
      "[Epoch 424] loss: 0.793\n",
      "[Epoch 425] loss: 0.794\n",
      "[Epoch 426] loss: 0.809\n",
      "[Epoch 427] loss: 0.779\n",
      "[Epoch 428] loss: 0.791\n",
      "[Epoch 429] loss: 0.767\n",
      "[Epoch 430] loss: 0.780\n",
      "[Epoch 431] loss: 0.767\n",
      "[Epoch 432] loss: 0.776\n",
      "[Epoch 433] loss: 0.741\n",
      "[Epoch 434] loss: 0.785\n",
      "[Epoch 435] loss: 0.768\n",
      "[Epoch 436] loss: 0.777\n",
      "[Epoch 437] loss: 0.760\n",
      "[Epoch 438] loss: 0.796\n",
      "[Epoch 439] loss: 0.783\n",
      "[Epoch 440] loss: 0.779\n",
      "[Epoch 441] loss: 0.779\n",
      "[Epoch 442] loss: 0.800\n",
      "[Epoch 443] loss: 0.798\n",
      "[Epoch 444] loss: 0.783\n",
      "[Epoch 445] loss: 0.784\n",
      "[Epoch 446] loss: 0.780\n",
      "[Epoch 447] loss: 0.793\n",
      "[Epoch 448] loss: 0.791\n",
      "[Epoch 449] loss: 0.808\n",
      "[Epoch 450] loss: 0.779\n",
      "[Epoch 451] loss: 0.758\n",
      "[Epoch 452] loss: 0.771\n",
      "[Epoch 453] loss: 0.793\n",
      "[Epoch 454] loss: 0.795\n",
      "[Epoch 455] loss: 0.801\n",
      "[Epoch 456] loss: 0.811\n",
      "[Epoch 457] loss: 0.801\n",
      "[Epoch 458] loss: 0.783\n",
      "[Epoch 459] loss: 0.779\n",
      "[Epoch 460] loss: 0.788\n",
      "[Epoch 461] loss: 0.747\n",
      "[Epoch 462] loss: 0.799\n",
      "[Epoch 463] loss: 0.789\n",
      "[Epoch 464] loss: 0.789\n",
      "[Epoch 465] loss: 0.782\n",
      "[Epoch 466] loss: 0.779\n",
      "[Epoch 467] loss: 0.773\n",
      "[Epoch 468] loss: 0.778\n",
      "[Epoch 469] loss: 0.780\n",
      "[Epoch 470] loss: 0.789\n",
      "[Epoch 471] loss: 0.761\n",
      "[Epoch 472] loss: 0.777\n",
      "[Epoch 473] loss: 0.776\n",
      "[Epoch 474] loss: 0.789\n",
      "[Epoch 475] loss: 0.772\n",
      "[Epoch 476] loss: 0.776\n",
      "[Epoch 477] loss: 0.808\n",
      "[Epoch 478] loss: 0.787\n",
      "[Epoch 479] loss: 0.780\n",
      "[Epoch 480] loss: 0.777\n",
      "[Epoch 481] loss: 0.804\n",
      "[Epoch 482] loss: 0.803\n",
      "[Epoch 483] loss: 0.789\n",
      "[Epoch 484] loss: 0.805\n",
      "[Epoch 485] loss: 0.796\n",
      "[Epoch 486] loss: 0.773\n",
      "[Epoch 487] loss: 0.751\n",
      "[Epoch 488] loss: 0.796\n",
      "[Epoch 489] loss: 0.780\n",
      "[Epoch 490] loss: 0.774\n",
      "[Epoch 491] loss: 0.782\n",
      "[Epoch 492] loss: 0.789\n",
      "[Epoch 493] loss: 0.798\n",
      "[Epoch 494] loss: 0.790\n",
      "[Epoch 495] loss: 0.776\n",
      "[Epoch 496] loss: 0.772\n",
      "[Epoch 497] loss: 0.784\n",
      "[Epoch 498] loss: 0.805\n",
      "[Epoch 499] loss: 0.770\n",
      "[Epoch 500] loss: 0.775\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on test set: -0.47\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57200abac2ff18432c53e10587ceb364acdd46eebe90c6833204d1f95e2c9eff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
