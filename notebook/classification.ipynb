{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils.dataset as dataset\n",
    "from models.lstm import ClassificationLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "PATH='D:\\\\Deutschland\\\\FUB\\\\master_thesis\\\\data\\\\gee\\\\output'\n",
    "DATA_DIR = os.path.join(PATH, 'monthly_mean')\n",
    "LABEL_CSV = 'label.csv'\n",
    "label_path = os.path.join(PATH, LABEL_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.01\n",
    "EPOCH = 100\n",
    "SEED = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for LSTM\n",
    "input_size = 5\n",
    "hidden_size = 20\n",
    "num_layers = 1\n",
    "num_classes = 21\n",
    "layer1_dim = 256\n",
    "layer2_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(x_data:np.ndarray, y_data:np.ndarray):\n",
    "    # embedding\n",
    "    embedding = nn.Embedding(8000, input_size)\n",
    "    # reduce dimention from (n, 1) to (n, )\n",
    "    y_data = y_data.reshape(-1)\n",
    "    x_set = torch.from_numpy(x_data)\n",
    "    y_set = torch.from_numpy(y_data)\n",
    "    x_set = embedding(x_set).detach()\n",
    "    return x_set, y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:nn.Module, epoch:int):\n",
    "    total_step = len(train_loader)\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # record training loss\n",
    "        if i % 40 == 0:\n",
    "            print('Epoch[{}/{}],Step[{}/{}],Loss:{:.4f}'\n",
    "            .format(epoch+1,EPOCH,i+40,total_step,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model:nn.Module):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for (values, labels) in val_loader:\n",
    "            values = values.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(values)\n",
    "            total += labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # dataset\n",
    "    x_data, y_data = dataset.load_csv_data(DATA_DIR, label_path)\n",
    "    x_set, y_set = build_dataset(x_data, y_data)\n",
    "    train_loader, val_loader = dataset.build_dataloader(x_set, y_set, BATCH_SIZE, SEED)\n",
    "    # model\n",
    "    model = ClassificationLSTM(input_size, hidden_size, layer1_dim, layer2_dim, num_layers, num_classes).to(device)\n",
    "    # loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), LR)\n",
    "    # train and validate model\n",
    "    for epoch in range(EPOCH):\n",
    "        train(model, epoch)\n",
    "        validate(model)\n",
    "    # save model\n",
    "    # torch.save(model, '../outputs/model.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57200abac2ff18432c53e10587ceb364acdd46eebe90c6833204d1f95e2c9eff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
