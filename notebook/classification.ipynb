{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LenovoSoftstore\\Anaconda\\envs\\yolov5\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "import torch.utils.data as Data\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils.csv as csv\n",
    "import utils.validation as val\n",
    "from models.transformer import TransformerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000, 32.0985,  7.0630, 17.9227, 11.9396, 20.1051,  3.0095, 25.0062])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = torch.tensor([24106, 751, 3413, 1345, 2019, 1199, 8010, 964])\n",
    "mx = max(samples)\n",
    "weight = mx / samples\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "PATH='D:\\\\Deutschland\\\\FUB\\\\master_thesis\\\\data\\\\gee\\\\output'\n",
    "DATA_DIR = os.path.join(PATH, 'daily')\n",
    "LABEL_CSV = 'label_pure.csv'\n",
    "label_path = os.path.join(PATH, LABEL_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.01\n",
    "EPOCH = 100\n",
    "SEED = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for Transformer model\n",
    "num_bands = 10\n",
    "seq_len = 25\n",
    "num_classes = 5\n",
    "d_model = 8\n",
    "nhead = 4\n",
    "num_layers = 1\n",
    "dim_feedforward = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_tensor(x_data:np.ndarray, y_data:np.ndarray):\n",
    "    x_set = torch.from_numpy(x_data)\n",
    "    y_set = torch.from_numpy(y_data)\n",
    "    # exchange dimension 0 and 1 of x_set depending on batch_first or not\n",
    "    x_set = x_set.transpose(0, 1)\n",
    "    # reduce dimention of y_set from (n, 1) to (n, )\n",
    "    y_set = y_set.view(-1)\n",
    "    return x_set, y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(x_set:Tensor, y_set:Tensor, batch_size:int, seed:int):\n",
    "    # dataset = Data.TensorDataset(x_set, y_set)\n",
    "    # # split dataset\n",
    "    # size = len(dataset)\n",
    "    # train_size, val_size = round(0.8 * size), round(0.2 * size)\n",
    "    # generator = torch.Generator().manual_seed(seed)\n",
    "    # train_dataset, val_dataset = Data.random_split(dataset, [train_size, val_size], generator)\n",
    "    x_train = x_set[:1105]\n",
    "    y_train = y_set[:1105]\n",
    "    x_val = x_set[1105:]\n",
    "    y_val = y_set[1105:]\n",
    "    train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "    val_dataset = Data.TensorDataset(x_val, y_val)\n",
    "    # data_loader\n",
    "    train_loader = Data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "    val_loader = Data.DataLoader(val_dataset,batch_size=len(val_dataset), shuffle=True,num_workers=4)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:nn.Module, epoch:int):\n",
    "    total_step = len(train_loader)\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # record training loss\n",
    "        if i % total_step == 0:\n",
    "            print('Epoch[{}/{}],Step[{}/{}],Loss:{:.4f}'\n",
    "            .format(epoch+1,EPOCH,i+total_step,total_step,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model:nn.Module):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for (values, labels) in val_loader:\n",
    "            values = values.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(values)\n",
    "            total += labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # dataset\n",
    "    x_data, y_data = csv.to_numpy(DATA_DIR, label_path)\n",
    "    x_set, y_set = numpy_to_tensor(x_data, y_data)\n",
    "    train_loader, val_loader = build_dataloader(x_set, y_set, BATCH_SIZE, SEED)\n",
    "    # model\n",
    "    model = TransformerClassifier(num_bands, seq_len, num_classes, d_model, nhead, num_layers, dim_feedforward).to(device)\n",
    "    # loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), LR)\n",
    "    # train and validate model\n",
    "    for epoch in range(EPOCH):\n",
    "        train(model, epoch)\n",
    "        validate(model)\n",
    "        break\n",
    "    # save model\n",
    "    # torch.save(model, '../outputs/model.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57200abac2ff18432c53e10587ceb364acdd46eebe90c6833204d1f95e2c9eff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
